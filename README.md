# MCPâ€‘Powered Insurance Voice Agent ğŸ™ï¸ğŸ¤–

An end-to-end modular voice agent built using the OpenAI Agents SDK and the Model Context Protocol (MCP). This framework demonstrates how to construct robust, voice-enabled conversational agents that orchestrate tools like RAG, web search, and SQLite via MCP.

---

## ğŸŒ Overview

This project showcases how to leverage the open-source **Model Context Protocol (MCP)**â€”a standardized middleware for LLM-tool interoperabilityâ€”to build a voice assistant capable of:

- Decoupling agent logic from tool backends
- Managing context securely and dynamically
- Orchestrating tool usage via a planner agent
- Scaling with plugâ€‘andâ€‘play tool services
- Operating with voice input/output using STT and TTS models

Youâ€™ll learn how to:

1. Capture and transcribe voice input
2. Use a Planner agent to determine tool calls
3. Invoke MCP-managed services (RAG, web search, SQLite)
4. Synthesize the agentâ€™s response and convert it to audio
5. Stream voice responses back to the user

---

## ğŸ”§ Features

- **MCP Tool Framework**: Standardized communication between agents and microservices
- **Voice Flow**: Chained STT â†’ Planner â†’ MCP tool-calling â†’ Response synthesis â†’ TTS
- **Tools Included**:
  - Custom RAG (Retrieval-Augmented Generation)
  - Web search agent powered by OpenAI
  - Built-in SQLite database agent
- **Insurance Demo**: Insurance-advisory agent showcases real-world context
- **Low Latency Voice Models**: Uses `gpt-4o-transcribe` (STT) and `gpt-4o-mini-tts` (TTS) by default

---

## ğŸ“¦ Installation

```bash
# Python dependencies
pip install asyncio ffmpeg ffprobe mcp openai openai-agents pydub scipy sounddevice uv nest_asyncio python-dotenv --quiet
pip install "openai-agents[voice]" --quiet
````

---

## âš™ï¸ Setup

1. Set your OpenAI API key in env file:

   ```
   OPENAI_API_KEY=**your opeanai api key**
   ```

2. Ensure `ffmpeg` is available on your system PATH.

---

## ğŸš€ Running the Voice Agent

Run the `main()` voice pipeline:

```bash
python main.py
```

It will:

1. Launch both MCP tool servers (RAG + web search, SQLite)
2. Capture streaming microphone input
3. Transcribe via STT
4. Plan tool calls and gather information
5. Synthesize a voice response via TTS
6. Stream audio back to the user

Interrupt with `Ctrl+C` to exit gracefully.

---

## ğŸ§­ Architecture

```
[Microphone] â†’ STT (gptâ€‘4oâ€‘transcribe)
        â†“
    [Planner Agent]
        â†“ invokes MCP tools â†’ [RAG / WebSearch / SQLite]
        â†“
    Synthesizes response â†’ TTS (gptâ€‘4oâ€‘miniâ€‘tts)
        â†“
     [Speakers]
```

---

## ğŸ§ª Example

> **User (voice):** â€œCan you tell me whatâ€™s covered under my home insurance policy?â€
> **Agent (voice):** â€œSure. Your policy covers fire damage, theft, and water damage up to \$150,000â€¦ \[continues]â€

---

## ğŸ“„ License

MIT License â€” see the [LICENSE](LICENSE) file.

---

## ğŸ“š References

* MCP-powered voice agent tutorial from OpenAI Cookbook ([cookbook.openai.com][3])
* Model Context Protocol details&#x20;
* Related tutorial: â€œBuilding a Voice Assistant with the Agents SDKâ€ ([cookbook.openai.com][4])

---

## ğŸš© Getting Help

Got questions or feedback? Open an issue or pull requestâ€”weâ€™d love your input!
